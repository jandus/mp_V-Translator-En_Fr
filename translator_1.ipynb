{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take, delete\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "    # open the file\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "    sents = text.strip().split('\\n')\n",
    "    sents = [i.split('\\t') for i in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_text(\"./data/deu-eng/deu.txt\")\n",
    "deu_eng = to_lines(data)\n",
    "deu_eng = array(deu_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "deu_eng = deu_eng[:50000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deu_eng.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
    "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(deu_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lowercase\n",
    "for i in range(len(deu_eng)):\n",
    "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
    "    \n",
    "    deu_eng[i,1] = deu_eng[i,1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go', 'Geh',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'],\n",
       "       ['Hi', 'Hallo',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
       "       ['Hi', 'Grüß Gott',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
       "       ...,\n",
       "       ['We took a wrong turn', 'Wir sind falsch abgebogen',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #823901 (jellorage) & #2112094 (freddy1)'],\n",
       "       ['We traveled together', 'Wir waren zusammen auf Reisen',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1582121 (Spamster) & #1600396 (Pfirsichbaeumchen)'],\n",
       "       ['We traveled together', 'Wir sind zusammen gereist',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1582121 (Spamster) & #1600398 (Pfirsichbaeumchen)']],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "deu_eng = delete(deu_eng, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go', 'Geh'],\n",
       "       ['Hi', 'Hallo'],\n",
       "       ['Hi', 'Grüß Gott'],\n",
       "       ...,\n",
       "       ['We took a wrong turn', 'Wir sind falsch abgebogen'],\n",
       "       ['We traveled together', 'Wir waren zusammen auf Reisen'],\n",
       "       ['We traveled together', 'Wir sind zusammen gereist']],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lowercase\n",
    "for i in range(len(deu_eng)):\n",
    "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
    "    \n",
    "    deu_eng[i,1] = deu_eng[i,1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['go', 'geh'],\n",
       "       ['hi', 'hallo'],\n",
       "       ['hi', 'grüß gott'],\n",
       "       ...,\n",
       "       ['we took a wrong turn', 'wir sind falsch abgebogen'],\n",
       "       ['we traveled together', 'wir waren zusammen auf reisen'],\n",
       "       ['we traveled together', 'wir sind zusammen gereist']],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "deu_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in deu_eng[:,0]:\n",
    "    eng_l.append(len(i.split()))\n",
    "\n",
    "for i in deu_eng[:,1]:\n",
    "    deu_l.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 6152\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 8\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deutch Vocabulary Size: 10112\n"
     ]
    }
   ],
   "source": [
    "# prepare Deutch tokenizer\n",
    "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
    "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
    "\n",
    "deu_length = 8\n",
    "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    seq = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare validation data\n",
    "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(RepeatVector(out_timesteps))\n",
    "    model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jandas/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = build_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)\n",
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "63/63 [==============================] - 142s 2s/step - loss: 4.2819 - val_loss: 2.7946\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.79464, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "63/63 [==============================] - 119s 2s/step - loss: 2.7203 - val_loss: 2.6917\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.79464 to 2.69172, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "63/63 [==============================] - 125s 2s/step - loss: 2.5747 - val_loss: 2.5269\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.69172 to 2.52694, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "63/63 [==============================] - 163s 3s/step - loss: 2.3994 - val_loss: 2.3858\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.52694 to 2.38577, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "63/63 [==============================] - 157s 2s/step - loss: 2.2532 - val_loss: 2.2648\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.38577 to 2.26480, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "63/63 [==============================] - 128s 2s/step - loss: 2.1097 - val_loss: 2.1997\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.26480 to 2.19966, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "63/63 [==============================] - 122s 2s/step - loss: 1.9890 - val_loss: 2.1153\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.19966 to 2.11526, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "63/63 [==============================] - 123s 2s/step - loss: 1.8687 - val_loss: 2.0108\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.11526 to 2.01083, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "63/63 [==============================] - 134s 2s/step - loss: 1.7745 - val_loss: 1.9444\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.01083 to 1.94443, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "63/63 [==============================] - 143s 2s/step - loss: 1.6685 - val_loss: 1.8822\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.94443 to 1.88216, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "63/63 [==============================] - 160s 3s/step - loss: 1.5803 - val_loss: 1.8097\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.88216 to 1.80966, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "63/63 [==============================] - 121s 2s/step - loss: 1.4801 - val_loss: 1.7296\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.80966 to 1.72957, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "63/63 [==============================] - 125s 2s/step - loss: 1.3943 - val_loss: 1.6775\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.72957 to 1.67752, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "63/63 [==============================] - 127s 2s/step - loss: 1.3028 - val_loss: 1.6416\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.67752 to 1.64165, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "63/63 [==============================] - 138s 2s/step - loss: 1.2178 - val_loss: 1.5820\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.64165 to 1.58200, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "63/63 [==============================] - 144s 2s/step - loss: 1.1384 - val_loss: 1.5370\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.58200 to 1.53699, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "63/63 [==============================] - 140s 2s/step - loss: 1.0687 - val_loss: 1.5005\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.53699 to 1.50046, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "63/63 [==============================] - 129s 2s/step - loss: 0.9991 - val_loss: 1.4808\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.50046 to 1.48084, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "63/63 [==============================] - 126s 2s/step - loss: 0.9336 - val_loss: 1.4447\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.48084 to 1.44468, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      "63/63 [==============================] - 147s 2s/step - loss: 0.8692 - val_loss: 1.4022\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.44468 to 1.40224, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "63/63 [==============================] - 162s 3s/step - loss: 0.7986 - val_loss: 1.3862\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.40224 to 1.38617, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "63/63 [==============================] - 146s 2s/step - loss: 0.7529 - val_loss: 1.3576\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.38617 to 1.35756, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "63/63 [==============================] - 166s 3s/step - loss: 0.6899 - val_loss: 1.3488\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.35756 to 1.34882, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n",
      "63/63 [==============================] - 157s 2s/step - loss: 0.6384 - val_loss: 1.3341\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.34882 to 1.33408, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "63/63 [==============================] - 183s 3s/step - loss: 0.5878 - val_loss: 1.3139\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.33408 to 1.31391, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "63/63 [==============================] - 188s 3s/step - loss: 0.5423 - val_loss: 1.2838\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.31391 to 1.28376, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "63/63 [==============================] - 189s 3s/step - loss: 0.4945 - val_loss: 1.2931\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.28376\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 194s 3s/step - loss: 0.4602 - val_loss: 1.2766\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.28376 to 1.27660, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "63/63 [==============================] - 189s 3s/step - loss: 0.4189 - val_loss: 1.2909\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.27660\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - 189s 3s/step - loss: 0.3840 - val_loss: 1.2618\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.27660 to 1.26177, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
     ]
    }
   ],
   "source": [
    "filename = 'model.h1.24_jan_19'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
    "          epochs=30, batch_size=512, \n",
    "          validation_split = 0.2,\n",
    "          callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jandas/opt/anaconda3/lib/python3.8/site-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.h1.24_jan_19')\n",
    "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == n:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert predictions into text (English)\n",
    "preds_text = []\n",
    "for i in preds:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)\n",
    "             \n",
    "        else:\n",
    "            if(t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)            \n",
    "        \n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>tom has betrayed us</td>\n",
       "      <td>tom betrayed us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>she smiled sadly</td>\n",
       "      <td>she smiled sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>tom looks crushed</td>\n",
       "      <td>tom looks uneasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>he went to the shop</td>\n",
       "      <td>he came</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>he got well again</td>\n",
       "      <td>he kept abroad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>i saw you looking</td>\n",
       "      <td>i saw tom saw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>tom was so busy</td>\n",
       "      <td>tom was up of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>where could he be</td>\n",
       "      <td>where is be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>my friend was shot</td>\n",
       "      <td>my man was a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>come on trust me</td>\n",
       "      <td>come you  me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>life is too short</td>\n",
       "      <td>its is short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>everybody saw it</td>\n",
       "      <td>everyone saw it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>try harder</td>\n",
       "      <td>try it once</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>he will be punished</td>\n",
       "      <td>he will be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>i speak swedish</td>\n",
       "      <td>i hate speak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>have fun you guys</td>\n",
       "      <td>have a great weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>give tom my thanks</td>\n",
       "      <td>take for  me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>do what you must</td>\n",
       "      <td>dont if you say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>tom combed his hair</td>\n",
       "      <td>tom hated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>is this car yours</td>\n",
       "      <td>is this your car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   actual                 predicted\n",
       "9980  tom has betrayed us      tom betrayed us     \n",
       "9981     she smiled sadly       she smiled sad     \n",
       "9982    tom looks crushed     tom looks uneasy     \n",
       "9983  he went to the shop             he came      \n",
       "9984    he got well again       he kept abroad     \n",
       "9985    i saw you looking         i saw tom saw    \n",
       "9986      tom was so busy         tom was up of    \n",
       "9987    where could he be          where is be     \n",
       "9988   my friend was shot          my man was a    \n",
       "9989     come on trust me          come you  me    \n",
       "9990    life is too short         its is short     \n",
       "9991     everybody saw it      everyone saw it     \n",
       "9992           try harder          try it once     \n",
       "9993  he will be punished           he will be     \n",
       "9994      i speak swedish         i hate speak     \n",
       "9995    have fun you guys  have a great weekend    \n",
       "9996   give tom my thanks          take for  me    \n",
       "9997     do what you must       dont if you say    \n",
       "9998  tom combed his hair           tom hated      \n",
       "9999    is this car yours      is this your car    "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>he is a dreamer</td>\n",
       "      <td>hes a grouch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066</th>\n",
       "      <td>give tom a call</td>\n",
       "      <td>write tom a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5369</th>\n",
       "      <td>shes a cutie</td>\n",
       "      <td>shes a emotional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8749</th>\n",
       "      <td>my right leg hurts</td>\n",
       "      <td>my arm hurts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>we made waffles</td>\n",
       "      <td>we made a pizza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7653</th>\n",
       "      <td>i hate beans</td>\n",
       "      <td>i hate lawyers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>you need to grow up</td>\n",
       "      <td>speak up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>theres no elevator</td>\n",
       "      <td>theres no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8707</th>\n",
       "      <td>what is tom eating</td>\n",
       "      <td>whats tom reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9647</th>\n",
       "      <td>im not good at that</td>\n",
       "      <td>im not at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4070</th>\n",
       "      <td>were trapped</td>\n",
       "      <td>were having the city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>didnt you hear that</td>\n",
       "      <td>didnt you hear that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7379</th>\n",
       "      <td>thats plastic</td>\n",
       "      <td>thats is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>she smiled sadly</td>\n",
       "      <td>she smiled sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3084</th>\n",
       "      <td>i am going to do it</td>\n",
       "      <td>ill do it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   actual                 predicted\n",
       "575       he is a dreamer         hes a grouch     \n",
       "3066      give tom a call          write tom a     \n",
       "5369         shes a cutie     shes a emotional     \n",
       "8749   my right leg hurts         my arm hurts     \n",
       "3408      we made waffles       we made a pizza    \n",
       "7653         i hate beans       i hate lawyers     \n",
       "2471  you need to grow up            speak up      \n",
       "276    theres no elevator           theres no      \n",
       "8707   what is tom eating    whats tom reading     \n",
       "9647  im not good at that            im not at     \n",
       "4070         were trapped  were having the city    \n",
       "6218  didnt you hear that   didnt you hear that    \n",
       "7379        thats plastic            thats is      \n",
       "9981     she smiled sadly       she smiled sad     \n",
       "3084  i am going to do it            ill do it     "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  36, 1639,   18, ...,    0,    0,    0],\n",
       "       [1030,    5,   35, ...,    0,    0,    0],\n",
       "       [   9,   25,   30, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 403,   26,    8, ...,   95,    0,    0],\n",
       "       [   1, 9008,   28, ...,    0,    0,    0],\n",
       "       [   3,    4,   31, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.reshape((testX.shape[0],testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX[1][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
